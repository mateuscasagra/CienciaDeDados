import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class VisualizacoesML:
    def __init__(self):
        self.cores_padrao = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
        plt.style.use('seaborn-v0_8')
        
    def plotar_clusters_2d(self, dados, labels_cluster, centroides=None, titulo="An√°lise de Clusters"):
        """Plota clusters em 2D usando PCA - VERS√ÉO COMBINADA (4 subplots)"""
        # Aplica PCA para reduzir para 2D
        pca = PCA(n_components=2)
        dados_2d = pca.fit_transform(dados)
        
        plt.figure(figsize=(12, 8))
        
        # Plot principal dos clusters
        plt.subplot(2, 2, 1)
        scatter = plt.scatter(dados_2d[:, 0], dados_2d[:, 1], c=labels_cluster, 
                            cmap='viridis', alpha=0.7, s=50)
        
        # Plot centroides se fornecidos
        if centroides is not None:
            centroides_2d = pca.transform(centroides)
            plt.scatter(centroides_2d[:, 0], centroides_2d[:, 1], 
                       c='red', marker='x', s=200, linewidths=3, label='Centroides')
            plt.legend()
        
        plt.title(f'{titulo} - Visualiza√ß√£o PCA')
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} da vari√¢ncia)')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} da vari√¢ncia)')
        plt.colorbar(scatter, label='Cluster')
        
        # Distribui√ß√£o dos clusters
        plt.subplot(2, 2, 2)
        unique_labels, counts = np.unique(labels_cluster, return_counts=True)
        plt.pie(counts, labels=[f'Cluster {i}' for i in unique_labels], 
               autopct='%1.1f%%', startangle=90)
        plt.title('Distribui√ß√£o dos Clusters')
        
        # Vari√¢ncia explicada pelo PCA
        plt.subplot(2, 2, 3)
        plt.bar(['PC1', 'PC2'], pca.explained_variance_ratio_)
        plt.title('Vari√¢ncia Explicada por Componente')
        plt.ylabel('Propor√ß√£o da Vari√¢ncia')
        
        # Caracter√≠sticas dos clusters
        plt.subplot(2, 2, 4)
        df_clusters = pd.DataFrame(dados)
        df_clusters['Cluster'] = labels_cluster
        
        # Calcula m√©dias por cluster
        medias_cluster = df_clusters.groupby('Cluster').mean()
        
        # Heatmap das caracter√≠sticas
        sns.heatmap(medias_cluster.T, annot=True, fmt='.2f', cmap='RdYlBu_r')
        plt.title('Caracter√≠sticas M√©dias por Cluster')
        plt.xlabel('Cluster')
        plt.ylabel('Vari√°veis')
        
        plt.tight_layout()
        plt.savefig('clusters_analise.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # AGORA GERA CADA GR√ÅFICO INDIVIDUALMENTE
        self.gerar_graficos_clusters_individuais(dados_2d, labels_cluster, centroides, pca, dados)
        
        return pca, dados_2d
    
    def gerar_graficos_clusters_individuais(self, dados_2d, labels_cluster, centroides, pca, dados):
        """Gera cada gr√°fico de cluster individualmente para uso nos slides"""
        
        # 1. Gr√°fico principal de clusters (scatter plot)
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(dados_2d[:, 0], dados_2d[:, 1], c=labels_cluster, 
                            cmap='viridis', alpha=0.7, s=50)
        if centroides is not None:
            centroides_2d = pca.transform(centroides)
            plt.scatter(centroides_2d[:, 0], centroides_2d[:, 1], 
                       c='red', marker='x', s=200, linewidths=3, label='Centroides')
            plt.legend()
        plt.title('Visualiza√ß√£o de Clusters - PCA 2D', fontsize=14, fontweight='bold')
        plt.xlabel(f'Primeira Componente Principal ({pca.explained_variance_ratio_[0]:.1%} da vari√¢ncia)')
        plt.ylabel(f'Segunda Componente Principal ({pca.explained_variance_ratio_[1]:.1%} da vari√¢ncia)')
        plt.colorbar(scatter, label='Cluster')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('src/machine_learning/clusters_pca_2d.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Distribui√ß√£o dos clusters (pizza)
        plt.figure(figsize=(8, 8))
        unique_labels, counts = np.unique(labels_cluster, return_counts=True)
        cores = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))
        plt.pie(counts, labels=[f'Cluster {i}' for i in unique_labels], 
               autopct='%1.1f%%', startangle=90, colors=cores)
        plt.title('Distribui√ß√£o dos Clusters', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig('src/machine_learning/distribuicao_clusters.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. Vari√¢ncia explicada pelo PCA
        plt.figure(figsize=(8, 6))
        plt.bar(['PC1', 'PC2'], pca.explained_variance_ratio_, color=['#1f77b4', '#ff7f0e'])
        plt.title('Vari√¢ncia Explicada por Componente Principal', fontsize=14, fontweight='bold')
        plt.ylabel('Propor√ß√£o da Vari√¢ncia')
        plt.ylim(0, 1)
        for i, v in enumerate(pca.explained_variance_ratio_):
            plt.text(i, v + 0.02, f'{v:.1%}', ha='center', fontsize=12, fontweight='bold')
        plt.grid(True, alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig('src/machine_learning/variancia_explicada_pca.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. Heatmap de caracter√≠sticas por cluster
        plt.figure(figsize=(10, 8))
        df_clusters = pd.DataFrame(dados)
        df_clusters['Cluster'] = labels_cluster
        medias_cluster = df_clusters.groupby('Cluster').mean()
        sns.heatmap(medias_cluster.T, annot=True, fmt='.2f', cmap='RdYlBu_r', 
                   cbar_kws={'label': 'Valor M√©dio'})
        plt.title('Caracter√≠sticas M√©dias por Cluster', fontsize=14, fontweight='bold')
        plt.xlabel('Cluster', fontsize=12)
        plt.ylabel('Vari√°veis', fontsize=12)
        plt.tight_layout()
        plt.savefig('src/machine_learning/heatmap_caracteristicas_clusters.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def plotar_importancia_features(self, importancias, nomes_features, titulo="Import√¢ncia das Vari√°veis"):
        """Plota import√¢ncia das features de forma detalhada - VERS√ÉO COMBINADA"""
        # Ordena por import√¢ncia
        indices = np.argsort(importancias)[::-1]
        
        plt.figure(figsize=(14, 8))
        
        # Gr√°fico principal de barras
        plt.subplot(2, 2, 1)
        cores = plt.cm.viridis(np.linspace(0, 1, len(importancias)))
        bars = plt.bar(range(len(importancias)), importancias[indices], color=cores)
        plt.title(titulo)
        plt.xlabel('Vari√°veis')
        plt.ylabel('Import√¢ncia')
        plt.xticks(range(len(importancias)), [nomes_features[i] for i in indices], rotation=45)
        
        # Adiciona valores nas barras
        for bar, imp in zip(bars, importancias[indices]):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{imp:.3f}', ha='center', va='bottom', fontsize=9)
        
        # Gr√°fico de pizza das top 5
        plt.subplot(2, 2, 2)
        top_5_indices = indices[:5]
        top_5_importancias = importancias[top_5_indices]
        top_5_nomes = [nomes_features[i] for i in top_5_indices]
        
        plt.pie(top_5_importancias, labels=top_5_nomes, autopct='%1.1f%%', startangle=90)
        plt.title('Top 5 Vari√°veis Mais Importantes')
        
        # Gr√°fico cumulativo
        plt.subplot(2, 2, 3)
        importancias_ordenadas = importancias[indices]
        importancias_cumulativas = np.cumsum(importancias_ordenadas)
        
        plt.plot(range(1, len(importancias) + 1), importancias_cumulativas, 'bo-')
        plt.axhline(y=0.8, color='r', linestyle='--', label='80% da import√¢ncia')
        plt.axhline(y=0.9, color='orange', linestyle='--', label='90% da import√¢ncia')
        plt.title('Import√¢ncia Cumulativa')
        plt.xlabel('N√∫mero de Vari√°veis')
        plt.ylabel('Import√¢ncia Cumulativa')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Tabela de ranking
        plt.subplot(2, 2, 4)
        plt.axis('off')
        
        ranking_texto = "RANKING DE IMPORTANCIA:\n\n"
        for i, idx in enumerate(indices[:8], 1):  # Top 8
            ranking_texto += f"{i:2d}o {nomes_features[idx]:<20} {importancias[idx]:.3f}\n"
        
        plt.text(0.1, 0.9, ranking_texto, transform=plt.gca().transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace')
        
        plt.tight_layout()
        plt.savefig('importancia_features.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # AGORA GERA CADA GR√ÅFICO INDIVIDUALMENTE
        self.gerar_graficos_importancia_individuais(importancias, nomes_features, indices)
        
        return indices
    
    def gerar_graficos_importancia_individuais(self, importancias, nomes_features, indices):
        """Gera cada gr√°fico de import√¢ncia individualmente"""
        
        # 1. Gr√°fico de barras principal (HORIZONTAL para melhor visualiza√ß√£o)
        plt.figure(figsize=(10, 8))
        cores = plt.cm.viridis(np.linspace(0, 1, len(importancias)))
        bars = plt.barh(range(len(importancias)), importancias[indices], color=cores)
        plt.yticks(range(len(importancias)), [nomes_features[i] for i in indices])
        plt.xlabel('Import√¢ncia', fontsize=12, fontweight='bold')
        plt.ylabel('Vari√°veis', fontsize=12, fontweight='bold')
        plt.title('Import√¢ncia das Vari√°veis (Random Forest)', fontsize=14, fontweight='bold')
        
        # Adiciona valores nas barras
        for i, (bar, imp) in enumerate(zip(bars, importancias[indices])):
            plt.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,
                    f'{imp:.3f}', ha='left', va='center', fontsize=10, fontweight='bold')
        
        plt.gca().invert_yaxis()
        plt.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        plt.savefig('src/machine_learning/importancia_features_barras.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Gr√°fico de pizza top 5
        plt.figure(figsize=(10, 8))
        top_5_indices = indices[:5]
        top_5_importancias = importancias[top_5_indices]
        top_5_nomes = [nomes_features[i] for i in top_5_indices]
        cores_pizza = plt.cm.Set3(range(5))
        plt.pie(top_5_importancias, labels=top_5_nomes, autopct='%1.1f%%', 
               startangle=90, colors=cores_pizza, textprops={'fontsize': 12, 'fontweight': 'bold'})
        plt.title('Top 5 Vari√°veis Mais Importantes', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig('src/machine_learning/importancia_top5_pizza.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def plotar_curvas_aprendizado(self, historico_treino, titulo="Curvas de Aprendizado"):
        """Plota curvas de aprendizado para modelos que t√™m hist√≥rico"""
        if not historico_treino:
            print("Nenhum hist√≥rico de treinamento fornecido.")
            return
        
        plt.figure(figsize=(12, 8))
        
        for nome_modelo, historico in historico_treino.items():
            if 'loss' in historico:
                plt.subplot(2, 2, 1)
                plt.plot(historico['loss'], label=f'{nome_modelo} - Loss')
                plt.title('Evolu√ß√£o da Loss')
                plt.xlabel('√âpoca')
                plt.ylabel('Loss')
                plt.legend()
                plt.grid(True, alpha=0.3)
            
            if 'accuracy' in historico:
                plt.subplot(2, 2, 2)
                plt.plot(historico['accuracy'], label=f'{nome_modelo} - Acur√°cia')
                plt.title('Evolu√ß√£o da Acur√°cia')
                plt.xlabel('√âpoca')
                plt.ylabel('Acur√°cia')
                plt.legend()
                plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('curvas_aprendizado.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def plotar_distribuicao_dados(self, dados, titulo="Distribui√ß√£o dos Dados"):
        """Plota distribui√ß√£o das vari√°veis nos dados"""
        df = pd.DataFrame(dados)
        
        # Calcula n√∫mero de subplots necess√°rios
        n_vars = len(df.columns)
        n_cols = 3
        n_rows = (n_vars + n_cols - 1) // n_cols
        
        plt.figure(figsize=(15, 5 * n_rows))
        
        for i, coluna in enumerate(df.columns, 1):
            plt.subplot(n_rows, n_cols, i)
            
            if df[coluna].dtype in ['object', 'category']:
                # Vari√°vel categ√≥rica
                contagens = df[coluna].value_counts()
                plt.bar(range(len(contagens)), contagens.values)
                plt.xticks(range(len(contagens)), contagens.index, rotation=45)
                plt.title(f'Distribui√ß√£o: {coluna}')
                plt.ylabel('Frequ√™ncia')
            else:
                # Vari√°vel num√©rica
                plt.hist(df[coluna], bins=20, alpha=0.7, edgecolor='black')
                plt.title(f'Distribui√ß√£o: {coluna}')
                plt.xlabel(coluna)
                plt.ylabel('Frequ√™ncia')
        
        plt.suptitle(titulo, fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig('distribuicao_dados.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def plotar_correlacoes(self, dados, titulo="Matriz de Correla√ß√£o"):
        """Plota matriz de correla√ß√£o das vari√°veis - VERS√ÉO COMBINADA"""
        df = pd.DataFrame(dados)
        
        # Seleciona apenas vari√°veis num√©ricas
        df_numeric = df.select_dtypes(include=[np.number])
        
        if df_numeric.empty:
            print("Nenhuma variavel numerica encontrada para correlacao.")
            return None
        
        plt.figure(figsize=(12, 10))
        
        # Matriz de correla√ß√£o
        corr_matrix = df_numeric.corr()
        
        # Subplot 1: Heatmap completo
        plt.subplot(2, 2, 1)
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', 
                   center=0, square=True, cbar_kws={'label': 'Correlacao'})
        plt.title('Matriz de Correlacao Completa')
        
        # Subplot 2: Correla√ß√µes mais fortes
        plt.subplot(2, 2, 2)
        # Pega correla√ß√µes acima de 0.5 (em valor absoluto)
        mask = np.abs(corr_matrix) > 0.5
        sns.heatmap(corr_matrix, mask=~mask, annot=True, fmt='.2f', 
                   cmap='RdBu_r', center=0, square=True)
        plt.title('Correlacoes Fortes (|r| > 0.5)')
        
        # Subplot 3: Distribui√ß√£o das correla√ß√µes
        plt.subplot(2, 2, 3)
        # Pega apenas o tri√¢ngulo superior (sem diagonal)
        correlacoes = corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]
        plt.hist(correlacoes, bins=20, alpha=0.7, edgecolor='black')
        plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
        plt.title('Distribuicao das Correlacoes')
        plt.xlabel('Correlacao')
        plt.ylabel('Frequencia')
        
        # Subplot 4: Top correla√ß√µes
        plt.subplot(2, 2, 4)
        plt.axis('off')
        
        # Encontra as correla√ß√µes mais fortes
        correlacoes_abs = np.abs(corr_matrix.values)
        np.fill_diagonal(correlacoes_abs, 0)  # Remove diagonal
        
        # Pega os √≠ndices das correla√ß√µes mais fortes
        indices_max = np.unravel_index(np.argsort(correlacoes_abs.ravel())[-10:], 
                                      correlacoes_abs.shape)
        
        texto_correlacoes = "TOP 10 CORRELACOES:\n\n"
        for i in range(len(indices_max[0])-1, -1, -1):  # Ordem decrescente
            row, col = indices_max[0][i], indices_max[1][i]
            if row != col:  # Evita diagonal
                var1 = df_numeric.columns[row]
                var2 = df_numeric.columns[col]
                corr_val = corr_matrix.iloc[row, col]
                texto_correlacoes += f"{var1} <-> {var2}: {corr_val:.3f}\n"
        
        plt.text(0.1, 0.9, texto_correlacoes, transform=plt.gca().transAxes,
                fontsize=10, verticalalignment='top', fontfamily='monospace')
        
        plt.suptitle(titulo, fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig('matriz_correlacao.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # AGORA GERA GR√ÅFICO INDIVIDUAL PRINCIPAL
        plt.figure(figsize=(12, 10))
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', 
                   center=0, square=True, cbar_kws={'label': 'Correlacao'}, 
                   linewidths=0.5, linecolor='gray')
        plt.title('Matriz de Correlacao - Vari√°veis Num√©ricas', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig('src/machine_learning/matriz_correlacao.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        return corr_matrix
    
    def plotar_dashboard_ml(self, resultados_clustering, resultados_classificacao, dados_originais):
        """Cria um dashboard completo com todos os resultados de ML"""
        fig = plt.figure(figsize=(20, 16))
        
        # T√≠tulo principal
        fig.suptitle('DASHBOARD MACHINE LEARNING - AN√ÅLISE DE ACIDENTES FATAIS', 
                    fontsize=20, fontweight='bold', y=0.98)
        
        # 1. Clusters (canto superior esquerdo)
        ax1 = plt.subplot(3, 4, 1)
        if 'dados_2d' in resultados_clustering:
            scatter = plt.scatter(resultados_clustering['dados_2d'][:, 0], 
                                resultados_clustering['dados_2d'][:, 1],
                                c=resultados_clustering['labels'], 
                                cmap='viridis', alpha=0.7, s=30)
            plt.title('Clusters de Acidentes', fontweight='bold')
            plt.xlabel('Componente Principal 1')
            plt.ylabel('Componente Principal 2')
            plt.colorbar(scatter, ax=ax1, label='Cluster')
        
        # 2. Distribui√ß√£o de clusters
        ax2 = plt.subplot(3, 4, 2)
        if 'labels' in resultados_clustering:
            unique_labels, counts = np.unique(resultados_clustering['labels'], return_counts=True)
            plt.pie(counts, labels=[f'Cluster {i}' for i in unique_labels], 
                   autopct='%1.1f%%', startangle=90)
            plt.title('Distribui√ß√£o dos Clusters', fontweight='bold')
        
        # 3. Compara√ß√£o de modelos de classifica√ß√£o
        ax3 = plt.subplot(3, 4, 3)
        if resultados_classificacao:
            modelos = list(resultados_classificacao.keys())
            f1_scores = [resultados_classificacao[m]['f1_score'] for m in modelos]
            
            cores = ['gold', 'silver', '#CD7F32', 'lightcoral'][:len(modelos)]
            bars = plt.bar(range(len(modelos)), f1_scores, color=cores)
            plt.title('F1-Score por Modelo', fontweight='bold')
            plt.ylabel('F1-Score')
            plt.xticks(range(len(modelos)), [m.replace('_', ' ').title() for m in modelos], 
                      rotation=45)
            
            # Adiciona valores nas barras
            for bar, score in zip(bars, f1_scores):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{score:.3f}', ha='center', va='bottom', fontsize=9)
        
        # 4. Matriz de confus√£o do melhor modelo
        ax4 = plt.subplot(3, 4, 4)
        if resultados_classificacao:
            melhor_modelo = max(resultados_classificacao.keys(), 
                              key=lambda x: resultados_classificacao[x]['f1_score'])
            cm = resultados_classificacao[melhor_modelo]['matriz_confusao']
            
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,
                       xticklabels=['N√£o Fatal', 'Fatal'],
                       yticklabels=['N√£o Fatal', 'Fatal'])
            plt.title(f'Matriz de Confus√£o\n{melhor_modelo.replace("_", " ").title()}', 
                     fontweight='bold')
        
        # 5-8. Distribui√ß√µes das vari√°veis principais
        df = pd.DataFrame(dados_originais)
        variaveis_principais = ['fase_dia', 'condicao_metereologica', 'causa_acidente', 'idade']
        
        for i, var in enumerate(variaveis_principais, 5):
            ax = plt.subplot(3, 4, i)
            
            if var in df.columns:
                if df[var].dtype in ['object', 'category'] or var != 'idade':
                    contagens = df[var].value_counts().head(8)  # Top 8
                    plt.bar(range(len(contagens)), contagens.values, alpha=0.7)
                    plt.xticks(range(len(contagens)), contagens.index, rotation=45)
                    plt.title(f'Distribui√ß√£o: {var.replace("_", " ").title()}', fontweight='bold')
                    plt.ylabel('Frequ√™ncia')
                else:
                    plt.hist(df[var], bins=15, alpha=0.7, edgecolor='black')
                    plt.title(f'Distribui√ß√£o: {var.replace("_", " ").title()}', fontweight='bold')
                    plt.xlabel(var.replace("_", " ").title())
                    plt.ylabel('Frequ√™ncia')
        
        # 9. Import√¢ncia das vari√°veis (se dispon√≠vel)
        ax9 = plt.subplot(3, 4, 9)
        if 'random_forest' in resultados_classificacao and hasattr(resultados_classificacao, 'importancias'):
            importancias = resultados_classificacao['random_forest'].get('importancias', [])
            if importancias:
                features = ['Fase Dia', 'Clima', 'Causa', 'Tipo', 'Idade', 'Sexo']
                plt.barh(features, importancias)
                plt.title('Import√¢ncia das Vari√°veis', fontweight='bold')
                plt.xlabel('Import√¢ncia')
        
        # 10. Estat√≠sticas gerais
        ax10 = plt.subplot(3, 4, 10)
        plt.axis('off')
        
        total_acidentes = len(df)
        acidentes_fatais = df['mortos'].sum() if 'mortos' in df.columns else 0
        taxa_letalidade = (acidentes_fatais / total_acidentes * 100) if total_acidentes > 0 else 0
        
        stats_texto = f"""
        ESTAT√çSTICAS GERAIS:
        
        üìä Total de Acidentes: {total_acidentes:,}
        üíÄ Acidentes Fatais: {acidentes_fatais:,}
        üìà Taxa de Letalidade: {taxa_letalidade:.1f}%
        
        üèÜ MELHOR MODELO:
        {melhor_modelo.replace('_', ' ').title() if resultados_classificacao else 'N/A'}
        
        üéØ F1-Score: {resultados_classificacao[melhor_modelo]['f1_score']:.3f if resultados_classificacao else 'N/A'}
        
        üìç CLUSTERS IDENTIFICADOS:
        {len(np.unique(resultados_clustering['labels'])) if 'labels' in resultados_clustering else 'N/A'} padr√µes distintos
        """
        
        plt.text(0.1, 0.9, stats_texto, transform=ax10.transAxes,
                fontsize=11, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        
        # 11-12. Gr√°ficos adicionais de an√°lise temporal
        ax11 = plt.subplot(3, 4, 11)
        if 'fase_dia' in df.columns:
            fase_mortos = df.groupby('fase_dia')['mortos'].agg(['count', 'sum']).reset_index()
            fase_mortos['taxa_letalidade'] = (fase_mortos['sum'] / fase_mortos['count'] * 100)
            
            plt.bar(range(len(fase_mortos)), fase_mortos['taxa_letalidade'], alpha=0.7)
            plt.xticks(range(len(fase_mortos)), fase_mortos['fase_dia'], rotation=45)
            plt.title('Taxa de Letalidade por Fase do Dia', fontweight='bold')
            plt.ylabel('Taxa de Letalidade (%)')
        
        ax12 = plt.subplot(3, 4, 12)
        if 'condicao_metereologica' in df.columns:
            clima_mortos = df.groupby('condicao_metereologica')['mortos'].agg(['count', 'sum']).reset_index()
            clima_mortos['taxa_letalidade'] = (clima_mortos['sum'] / clima_mortos['count'] * 100)
            
            # Pega apenas os top 6 para visualiza√ß√£o
            clima_top = clima_mortos.nlargest(6, 'count')
            plt.bar(range(len(clima_top)), clima_top['taxa_letalidade'], alpha=0.7)
            plt.xticks(range(len(clima_top)), clima_top['condicao_metereologica'], rotation=45)
            plt.title('Taxa de Letalidade por Clima', fontweight='bold')
            plt.ylabel('Taxa de Letalidade (%)')
        
        plt.tight_layout()
        plt.savefig('dashboard_ml_completo.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig
    
    def criar_dashboard_ml(self, resultados_clustering, resultados_classificacao, metricas):
        """
        Cria um dashboard completo integrando clustering e classifica√ß√£o.
        Retorna a figura do Plotly para uso no Streamlit.
        """
        try:
            # Configurar subplots
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('Clusters de Acidentes', 'Performance dos Modelos', 
                              'Import√¢ncia das Features', 'Matriz de Confus√£o'),
                specs=[[{"type": "scatter"}, {"type": "bar"}],
                       [{"type": "bar"}, {"type": "heatmap"}]]
            )
            
            # 1. Clusters (usando PCA para 2D)
            if 'dados_pca' in resultados_clustering and 'labels' in resultados_clustering:
                dados_pca = resultados_clustering['dados_pca']
                labels = resultados_clustering['labels']
                
                for cluster in np.unique(labels):
                    mask = labels == cluster
                    fig.add_trace(
                        go.Scatter(
                            x=dados_pca[mask, 0],
                            y=dados_pca[mask, 1],
                            mode='markers',
                            name=f'Cluster {cluster}',
                            marker=dict(size=8, opacity=0.7)
                        ),
                        row=1, col=1
                    )
            
            # 2. Performance dos modelos
            if 'comparacao' in resultados_classificacao:
                comp = resultados_classificacao['comparacao']
                modelos = list(comp.keys())
                f1_scores = [comp[modelo]['f1'] for modelo in modelos]
                
                fig.add_trace(
                    go.Bar(
                        x=modelos,
                        y=f1_scores,
                        name='F1-Score',
                        marker_color='lightblue'
                    ),
                    row=1, col=2
                )
            
            # 3. Import√¢ncia das features (Random Forest)
            if 'feature_importance' in resultados_classificacao:
                features = resultados_classificacao['feature_importance']['features']
                importancias = resultados_classificacao['feature_importance']['importances']
                
                fig.add_trace(
                    go.Bar(
                        x=importancias,
                        y=features,
                        orientation='h',
                        name='Import√¢ncia',
                        marker_color='lightgreen'
                    ),
                    row=2, col=1
                )
            
            # 4. Matriz de confus√£o do melhor modelo
            if 'melhor_modelo' in metricas and 'matriz_confusao' in metricas['melhor_modelo']:
                matriz = metricas['melhor_modelo']['matriz_confusao']
                
                fig.add_trace(
                    go.Heatmap(
                        z=matriz,
                        colorscale='Blues',
                        showscale=True
                    ),
                    row=2, col=2
                )
            
            # Layout
            fig.update_layout(
                title_text="Dashboard Machine Learning - Acidentes Fatais",
                showlegend=True,
                height=800,
                template='plotly_white'
            )
            
            print("‚úÖ Dashboard ML completo criado!")
            return fig
            
        except Exception as e:
            print(f"‚ùå Erro ao criar dashboard ML: {e}")
            return None